# -*- coding: utf-8 -*-
"""ml-brain-tumor-model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pgrFtyaPM6Sg-2JsqX4NvAF7yUT_dhgY

<h1>Enhancing Neuro-oncological Diagnosis: A Deep Learning Architecture for High-Accuracy Classification of Meningioma, Glioma, and Pituitary Brain Tumors in MRI Scans
</h1>

> EfficientNet-B2
<br>
> Cassandra Caluag, 2025 CSEF

# Load Brain Tumor Dataset into Colab Notebook

---
"""

!pip install opendatasets

import opendatasets as od
od.download("https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset")

# CORE PYTORCH & TORCHVISION
# -----------------------------------
import torch  # main pytorch library
import torch.nn as nn  # neural network layers, loss functions
import torch.optim as optim  # optimization algorithms (adam!)
from torch.utils.data import Dataset, DataLoader  # custom datasets + efficient batching/shuffling

from torchvision import transforms  # data augmentation and preprocessing
from torchvision.datasets import ImageFolder  # loads image data organized by folder structure


# MODEL ARCHITECTURE
# -----------------------------------
import timm  # access to pretrained efficientnet-b2


# EVALUATION & METRICS
# -----------------------------------
from sklearn.model_selection import train_test_split  # split dataset into train/val sets
from sklearn.metrics import confusion_matrix, f1_score  # performance metrics
import seaborn as sns  # for confusion matrix heatmaps
import matplotlib.pyplot as plt  # for plotting metrics, predictions, etc.
import matplotlib as mpl  # advanced plotting customization


# UTILITIES
#-----------------------------------
from tqdm.notebook import tqdm  # progress bars during training/testing
from PIL import Image  # image loading and manipulation
import pandas as pd  # dataframes for structured data logging
import numpy as np  # numerical operations
import os  # file path navigation & hashing
import hashlib  # for checking duplicates; data preprocessing
import random # for plotting random mri images

"""# Remove Duplicate Images
---

We must ensure that there are no duplicates to avoid skewing model performance/accuracy.
"""

def remove_dupes(image_folder):
    hashes = {}
    duplicates = []
    total = 0

    # loop thru files in folder
    for root, dirs, files in os.walk(image_folder):
        for file in files:
            if file.endswith('.jpg'):
                file_path = os.path.join(root, file)

                # calculate hash for image
                hash = hashlib.md5(open(file_path, 'rb').read()).hexdigest()

                # see if hash already exists
                if hash in hashes:
                    duplicates.append(file_path)  # add to duplicates list
                else:
                    hashes[hash] = file_path

    # remove duplicates
    for duplicate in duplicates:
        os.remove(duplicate)
        print(f"Removed duplicate: {duplicate}")
        total += 1

    return total

# specify folder containing images
image_folder = '/content/brain-tumor-mri-dataset'
remove_dupes(image_folder)

"""# Define PyTorch Dataset (Brain Tumor Dataset Object)

---

A PyTorch Dataset allows adequate handling + transformation of the data, making it compatible with the PyTorch framework
"""

class BrainTumorDataset(Dataset):
  def __init__(self, data_dir, transform=None):
    self.data = ImageFolder(data_dir, transform=transform)
  def __len__(self):
    return len(self.data)
  def __getitem__(self, idx):
    return self.data[idx]

"""# Data Preparation

---

<h2>Define Data Transformations</h2>

*   Transformations applied ensure data is in the right format
*   Can also diversify data, potentially leading to better performance
"""

transform = transforms.Compose([
    transforms.Resize((260, 260)), # efficientnet-b2 img size
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # standard normalization for imagenet images
])

ImageFolder("/content/brain-tumor-mri-dataset/Training").class_to_idx

"""Our label is a number, but we want it to be a word. Luckily, each number label correlates to a word label for easier understanding."""

# before transforms! (no transforms = NT)
training_NT = BrainTumorDataset("/content/brain-tumor-mri-dataset/Training")
image, label = training_NT[888]
print("Label:", label)
image

full_training = BrainTumorDataset("/content/brain-tumor-mri-dataset/Training", transform=transform)
image, label = full_training[888]
print("Label:", label)
image

dataset = full_training

# create dict for idx (val) : class name (key)
class_names_dict = {v: k for k, v in ImageFolder("/content/brain-tumor-mri-dataset/Training").class_to_idx.items()}

# num of images; 5x4=20
num_images_to_display = 15

# get random indices
random_indices = random.sample(range(len(dataset)), num_images_to_display)

# create grid of subplots (for each mri scan)
fig, axes = plt.subplots(3, 5, figsize=(13, 10))

axes = axes.ravel() # flatten 2d array -> easier iteration

# process each img (based on index)
for i, idx in enumerate(random_indices):

    # get the image and label from the dataset
    image, label = dataset[idx]

    # pytorch tensors usually are [channels, width, height]
    # matplotlib expect [height, width, channels]
    # permute reorders the dimensions!
    image_np = image.permute(1, 2, 0).numpy()

    if image_np.shape[-1] == 3:
        image_np = np.dot(image_np[...,:3], [0.2989, 0.5870, 0.1140]) # weighted sum of rgb to convert to grayscale!

    axes[i].imshow(image_np, cmap="gray_r")
    axes[i].set_title(class_names_dict[label])
    axes[i].axis('off')

plt.tight_layout()
plt.show()

"""<h2>Split Training Data into Training and Validation</h2>




"""

train_len = len(full_training) # how many images in the training dataset
train_len

tst = BrainTumorDataset("/content/brain-tumor-mri-dataset/Testing")
test_len = len(tst) # how many images in testing dataset
test_len

tst = list(tst)

full_dataset = train_len + test_len
print("There are {} images in the Brain Tumor Dataset.".format(full_dataset))

"""There are significantly more training images than testing images. Additionally, we need a validation dataset to evaluate the model's performance after every training epoch. So, we need to split the training dataset -> training and validation data."""

training_labels = [label for _, label in full_training] # obtain labels for each image in training dataset

from collections import Counter
train_key = Counter(training_labels)
num_glioma = train_key[0]
num_meningioma = train_key[1]
num_notumor = train_key[2]
num_pituitary = train_key[3]
print("Number of glioma MRI slices:", train_key[0])
print("Number of meningioma MRI slices:", train_key[1])
print("Number of MRI slices wih no tumors:", train_key[2])
print("Number of pituitary MRI slices:", train_key[3])

training_labels[:5] # Data is not shuffled yet, so first five will be glioma tumors.

"""Since each class has around the same number of files, this indicates that the training data is relatively balanced."""

X_train, X_val, y_train, y_val = train_test_split(full_training, training_labels, test_size=0.25, stratify=training_labels, random_state=8)

print(len(X_train))

print(len(X_val))

"""```stratify=training_labels``` ensures that the distribution of classes in new training and validations datasets is similar to the distribution in the original training dataset.
*   without stratification, the classes will not be distributed evenly, introducing bias to the model.
* stratification helps create more reliable and balanced training and datasets

```X_train``` or ```X_val``` represents the MRI scan image (the features) for training or validation

```y_train``` or ```y_val``` represents the tumor class (target variable) for training or validation

<h2> Split Training Dataset </h2>

*   training images to gauge model performance (provide quantitative performance metrics like accuracy, F1-score)
*   training images for 'real world' testing - provide visualizations using gradcam and probabilities
"""

print(test_len)

test_labels = [label for _, label in tst] # get labels for training dataset

test_key = Counter(test_labels)
num_glioma = test_key[0]
num_meningioma = test_key[1]
num_notumor = test_key[2]
num_pituitary = test_key[3]

print("Number of glioma MRI slices:", test_key[0])
print("Number of meningioma MRI slices:", test_key[1])
print("Number of MRI slices wih no tumors:", test_key[2])
print("Number of pituitary MRI slices:", test_key[3])

full_key = train_key + test_key

# data
labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']
sizes = [full_key[0]/4, full_key[1]/4, full_key[2]/4, full_key[3]/4]  # percentage values
colors = ['#738093', '#9FBDBF', '#CFD9DD', '#8AA0AA']

# create pie chart
plt.figure(figsize=(6,6))
plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90, textprops={'fontsize': 13})
plt.title('Brain Tumor MRI Dataset Data Distribution', fontsize=15)
plt.show()

X_test, X_viz, y_test, y_viz = train_test_split(tst, test_labels, test_size=0.003, stratify=test_labels)

print(len(X_viz))

print(len(X_test))

"""# Create Model Architecture

---

w/ EfficientNet-B2 pre-trained model!
* EfficientNet-B2's 9.2 million parameters provided sufficient model capacity to learn complex anatomical features in brain scans without requiring the computational resources of larger architectures like EfficientNet-B4 (19M parameters) or ResNet-50 (25M parameters). This made it ideal for training on Google Colab's GPU resources while still achieving clinical-grade performance.
"""

print(len(X_train))
print(len(X_val))

class BrainTumorClassifier(nn.Module):
  def __init__(self, num_classes=4):
    super(BrainTumorClassifier, self).__init__()
    self.base_model = timm.create_model("efficientnet_b2", pretrained=True)
    self.features = nn.Sequential(*list(self.base_model.children())[:-1])
    enet_out_size = self.base_model.num_features
    print(enet_out_size)
    self.classifier = nn.Linear(enet_out_size, num_classes)

  def forward(self, x):
    x = self.features(x)
    output = self.classifier(x)
    return output

model = BrainTumorClassifier(num_classes=4)

"""# Training and Validation Loop

---

First, we have to define the loss function (```criterion```) and the optimizer

```criterion```: measures how much the predictions are off from the actual true class
* Cross Entropy Loss is the best loss function for multi-classification models, since it best accurately measures the difference between the predicted class and the target class, guiding the model's learning process

```optimizer```: adjusts weights and biases to minimize loss; iteratively refines the model's performance to improve accuracy
* Adam (Adaptive Moment Estimation) allows for faster convergence (quicker model training, a stable state where the model does not learn much after stability)
"""

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)

"""Key Hyperparameter: Learning Rate
* ```lr``` controls how much the model updates its weights after how fast the model learns for each step

step = one optimization update
"""

train_loader = DataLoader(X_train, batch_size=32, shuffle=True)
val_loader = DataLoader(X_val, batch_size=32, shuffle=True)

"""Now, we can define the training + validation loop, and train the model!"""

num_epochs = 5
train_losses, val_losses = [], []

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

for epoch in range(num_epochs):
  # set model to train
  model.train()
  running_loss = 0.0
  correct = 0
  for images, labels in tqdm(train_loader, desc="Training Loop"):
    images, labels = images.to(device), labels.to(device)
    optimizer.zero_grad()
    outputs = model(images)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()
    running_loss += loss.item() * images.size(0)
  train_loss = running_loss / len(train_loader.dataset)
  train_losses.append(train_loss)

  # set model to evaluate - use validation data to validate training
  model.eval()
  running_loss = 0.0
  with torch.no_grad():
    for images, labels in tqdm(val_loader, desc="Validation Loop"):
      images, labels = images.to(device), labels.to(device)
      outputs = model(images)
      loss = criterion(outputs, labels)
      running_loss += loss.item() * images.size(0)
  val_loss = running_loss / len(val_loader.dataset)
  val_losses.append(val_loss)

  num_epoch = epoch + 1
  print("Epoch: {} ----- Train Loss: {} ------ Validation Loss: {} ------".format(num_epoch, train_loss, val_loss))

torch.save(model.state_dict(), 'efficientnet_b2_brain_tumor.pth')

"""# Evaluate and Visualize Model Performance


---


"""

test_loader = DataLoader(X_test, batch_size=32, shuffle=False)

"""Key Hyperparameter: Batch Size

* the number of training samples the model processes before the weights are updated
"""

X_test_transformed = [(transform(img), label) for img, label in X_test]

# Now create the DataLoader with the transformed images
test_loader = DataLoader(X_test_transformed, batch_size=32, shuffle=False)

all_accuracies = []
all_f1_scores = []

model.eval()
total = 0
correct = 0
true_labels = []
predicted_labels = []

with torch.no_grad():
  for images, labels in tqdm(test_loader, desc=f"Testing"):
    images, labels = images.to(device), labels.to(device)

    # obtain model predictions
    outputs = model(images)

    _, predicted = torch.max(outputs, 1)

    # add predicted and true labels to respective lists
    true_labels.extend(labels.cpu().numpy())
    predicted_labels.extend(predicted.cpu().numpy())

    total += labels.size(0)
    correct += (predicted == labels).sum().item()


# calculate accuracy for this run!
accuracy = correct / total

# calculate avg f1-score for this run!
f1 = f1_score(true_labels, predicted_labels, average="weighted")

print(f"Run {1} - Accuracy: {accuracy*100:.2f}% - F1-Score: {f1:.2f}")

# calculate and print the accuracy and f1-score for this run!
print(f"\nAccuracy of Model: {accuracy*100:.2f}%")
print(f"F1 Score of Model: {f1:.2f}")

"""<h3>Confusion Matrix</h3>

* a visual depiction of model performance by depicting the image predictions compared to true labels
* shows the number of true positives (TP), false positives (FP), false negatives (FN) which can be used to calculate F1 Score
"""

cm = confusion_matrix(true_labels, predicted_labels)
print("Confusion Matrix:\n", cm)

# visualize confusion matrix with a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="bone_r", xticklabels=["Meningioma", "Pituitary", "Glioma", "No Tumor"], yticklabels=["Meningioma", "Pituitary", "Glioma", "No Tumor"])
plt.title("\nConfusion Matrix\n", size=23, color="#202026")
plt.xlabel("\nPredicted\n", size=20, color="#6C7B88")
plt.ylabel("\nTrue\n", size=20, color="#36364C")
plt.xticks(fontsize=10, color="#69737D")
plt.yticks(fontsize=10, color="#434860")
plt.show()

"""Show F1 Score for each Class"""

from sklearn.metrics import precision_score, recall_score

precision = precision_score(true_labels, predicted_labels, average=None)
recall = recall_score(true_labels, predicted_labels, average=None)
f1 = f1_score(true_labels, predicted_labels, average=None)

class_names = ["glioma", "meningioma", "no_tumor", "pituitary"]


# display precision and recall for each class!
for i, class_name in enumerate(class_names):
    print(f"Class: {class_name}")
    print(f"  Precision: {precision[i]}")
    print(f"  Recall: {recall[i]}")
    print(f"  F1-Score: {f1[i]}")
    print("-" * 30)

"""<h3>Training vs. Validation Loss</h3>

* measures how well model is performing, based on training and validation data for each epoch
"""

plt.plot(train_losses, label='Training Loss', color="#52638A")
plt.plot(val_losses, label='Validation Loss', color="#9AB3AA")
plt.xlabel('Epochs', size=17)
plt.ylabel('Loss', size=17)
plt.title('Training vs Validation Loss', size=17)
plt.legend()
plt.show()

"""# Test Model (with Probability Visualizations)

---


"""

transform = transforms.Compose([
    transforms.Resize((260, 260)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # standard normalization for imagenet images
])

class_key = {v:k for k, v in ImageFolder("/content/brain-tumor-mri-dataset/Testing").class_to_idx.items()}

class_key

from PIL import Image
import cv2
import numpy as np

def preprocess_image(image_path, transform):
    image = Image.open(image_path).convert('RGB')  # open the image and convert to RGB
    return image, transform(image)

# predict using model!
def predict(model, image_tensor, device):
    model.eval()
    with torch.no_grad():
        image_tensor = image_tensor.to(device)
        outputs = model(image_tensor)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
    return probabilities.cpu().numpy().flatten()

# visualize - image, probabilities (w/ bar)
def visualize_predictions(original_image, label, probabilities, class_names):
    fig, axarr = plt.subplots(1, 2, figsize=(14, 7))

    # display image
    axarr[0].imshow(original_image)
    axarr[0].set_title(label, fontweight='bold')
    axarr[0].axis("off")

    # display set of predictions for each class
    axarr[1].barh(class_names, probabilities, color="#516178")

    # since the image is a numpy array, use numpy syntax to determine class of highest probability
    prediction_idx = np.argmax(probabilities)
    prediction = class_key[prediction_idx]

    axarr[1].set_xlabel("Probabilities", size=17, fontweight="bold")
    axarr[1].set_title("Class Predictions", size=17, fontweight="bold")
    axarr[1].set_xlim(0, 1)

    axarr[0].set_title("Correct Class: {}".format(class_key[label].upper()), size=17, fontweight="bold")


    plt.tight_layout()
    plt.show()

"""Let's use X_viz (data allocated + separated from the test dataset) to visually depict the model's performance!"""

print(X_viz)

test_image, label = X_viz[0]
class_key[label] # actual class!

# GRAD-CAM
!pip install grad-cam
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget

# load model; instantiated from BrainTumorClassifier class
model = BrainTumorClassifier(num_classes=4)

# Load the saved state dictionary into your BrainTumorClassifier model
model.load_state_dict(torch.load('efficientnet_b2_brain_tumor.pth', map_location=torch.device('cpu')))
model.eval()

# Move model to device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

# access last layer of model!
target_layers = [model.base_model.blocks[-1]]

# transformation defined earlier; but can put here for reference!
transform = transforms.Compose([
    transforms.Resize((260, 260)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

def gradcam(model, image_input, target_layers, device, transform, class_key):
  if isinstance(image_input, str):
    img = Image.open(image_input).convert('RGB')
  elif isinstance(image_input, Image.Image):
    img = image_input.convert('RGB')
  else:
    raise TypeError("image_input must be a string (file path) or a PIL Image object")

  input_tensor = transform(img).unsqueeze(0)  # add batch dimension
  input_tensor = input_tensor.to(device) # move input tensor to device

  # run gradcam by performing forward pass to get predicted class for image
  output = model(input_tensor)
  _, predicted_idx = torch.max(output, 1)
  predicted_class = predicted_idx.item()

  # define target for gradcam!
  targets = [ClassifierOutputTarget(predicted_class)]

  # initialize gradcam
  cam = GradCAM(model=model, target_layers=target_layers)

  # compute heatmap
  grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0]  # [0] = single image cam

  # visualize heatmap
  img_np = np.array(img.resize((260, 260))) / 255.0
  if img_np.ndim == 2: # Convert grayscale to RGB if necessary
      img_np = np.stack([img_np]*3, axis=-1)

  # superimpose
  visualization = show_cam_on_image(img_np, grayscale_cam, use_rgb=True)

  # display
  plt.imshow(visualization)
  plt.axis('off')
  plt.title(f"Grad-CAM: Focus for Predicted Class - {class_key[predicted_class].upper()}")
  plt.show()

# preprocess image!
original_image = test_image.convert('RGB') # ensure in RGB format
image_tensor = transform(original_image)  # apply transformations
image_tensor = image_tensor.unsqueeze(0) # make image tensor compatible w/ model input requirements

probabilities = predict(model, image_tensor, device)

class_names = ["glioma", "meningioma", "no_tumor", "pituitary"]
visualize_predictions(original_image, label, probabilities, class_names)

probabilities

gradcam(model, test_image, target_layers, device, transform, class_key)

test_image, label = X_viz[1]
class_key[label] # actual class!

original_image = test_image.convert('RGB')
image_tensor = transform(original_image)
image_tensor = image_tensor.unsqueeze(0)

probabilities = predict(model, image_tensor, device)

class_names = ["glioma", "meningioma", "no_tumor", "pituitary"]
visualize_predictions(original_image, label, probabilities, class_names)

probabilities

gradcam(model, test_image, target_layers, device, transform, class_key)

test_image, label = X_viz[2]
class_key[label] # actual class!

original_image = test_image.convert('RGB')
image_tensor = transform(original_image)
image_tensor = image_tensor.unsqueeze(0)

probabilities = predict(model, image_tensor, device)

class_names = ["glioma", "meningioma", "no_tumor", "pituitary"]
visualize_predictions(original_image, label, probabilities, class_names)

probabilities

gradcam(model, test_image, target_layers, device, transform, class_key)

test_image, label = X_viz[3]
class_key[label] # actual class!

original_image = test_image.convert('RGB')
image_tensor = transform(original_image)
image_tensor = image_tensor.unsqueeze(0)

probabilities = predict(model, image_tensor, device)

class_names = ["glioma", "meningioma", "no_tumor", "pituitary"]
visualize_predictions(original_image, label, probabilities, class_names)

probabilities

gradcam(model, test_image, target_layers, device, transform, class_key)